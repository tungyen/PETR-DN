apiVersion: v1
kind: Pod
metadata:
  name: tungyen-2852
  namespace: ucsd-haosulab
  annotations:
    yunikorn.apache.org/allow-preemption: "true"
spec:
  tolerations:
    - key: "nautilus.io/nrp-testing"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
  containers:
    - name: gpu-container
      image: pytorch/pytorch:1.9.0-cuda11.1-cudnn8-devel
      # image: tungyenchiang/resample-image
      # imagePullPolicy: Always
      args: ["sleep", "infinity"]
      resources:
        requests:
          cpu: "4"
          memory: "32Gi"
          ephemeral-storage: "30Gi"
          nvidia.com/gpu: "2"
        limits:
          cpu: "4"
          memory: "32Gi"
          ephemeral-storage: "30Gi"
          nvidia.com/gpu: "2"
      volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        - name: yen-fast-vol-285v2
          mountPath: /yen-fast-vol-285v2
  volumes:
    - name: dshm # shared memory, required for the multi-worker dataloader
      emptyDir:
        medium: Memory
    - name: yen-fast-vol-285v2
      persistentVolumeClaim:
        claimName: yen-fast-vol-285v2
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              # - key: nautilus.io/group
              #   operator: In
              #   values:
              #     - haosu
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-GeForce-RTX-3090
